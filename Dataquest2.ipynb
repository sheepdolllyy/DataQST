{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Hacker News Posts\n",
    "In this project, we'll work with a data set of submissions to popular technology site [Hacker News](https://news.ycombinator.com/).\n",
    "\n",
    "Hacker News is a site started by the startup incubator [Y Combinator](https://www.ycombinator.com/), where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "We can find the data set [here](https://www.kaggle.com/hacker-news/hacker-news-posts), but note that it has almost 300,000 rows. We need only \"full\" rows, that has comments, links, dates of creating, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clearing data\n",
    "The first step of our data working is clearing data.\n",
    "Below are descriptions of the columns:\n",
    "\n",
    "- **id**: The unique identifier from Hacker News for the post\n",
    "- **title**: The title of the post\n",
    "- **url**: The URL that the posts links to, if it the post has a URL\n",
    "- **num_points**: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "- **num_comments**: The number of comments that were made on the post\n",
    "- **author**: The username of the person who submitted the post\n",
    "- **created_at**: The date and time at which the post was submitted\n",
    "***\n",
    "For the first we need to open our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293120"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from csv import *\n",
    "opened_file = open('hacker_news.csv', encoding = 'utf-8')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "len(hn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our dataset has 293120 rows. \n",
    "***\n",
    "The second step will be removing non-comments rows. The number of comments is 5-th row in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80402"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 1\n",
    "for row in hn[1:]:\n",
    "    num_com = int(row[4])\n",
    "    if num_com == 0:\n",
    "        del hn[ind]\n",
    "        ind -= 1\n",
    "    ind += 1\n",
    "len(hn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After clearing non-comments records we have 80402 rows.\n",
    "***\n",
    "Now we have only \"full\" recordings. But its too much to our analizes. Let's remove random 75% of our dataset. We will have almost 20000 records. This will be enougth to our analize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23348"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint\n",
    "ind = 1\n",
    "for row in hn[1:]:\n",
    "    rand_num = randint(0,99)\n",
    "    title = row[1]\n",
    "    if rand_num <= 70: #and not title.lower().startswith('ask hn'):\n",
    "        del hn[ind]\n",
    "        ind -= 1\n",
    "    ind += 1\n",
    "len(hn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look on the first five rows of **hs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'],\n",
       " ['12578311',\n",
       "  'Americas Lost Boys: Men who choose video games over work',\n",
       "  'https://www.firstthings.com/blogs/firstthoughts/2016/08/americas-lost-boys',\n",
       "  '5',\n",
       "  '1',\n",
       "  'jseliger',\n",
       "  '9/26/2016 0:31'],\n",
       " ['12577883',\n",
       "  'LXQt 0.11 Released',\n",
       "  'http://lxqt.org/release/2016/09/24/lxqt-011-et-al/',\n",
       "  '40',\n",
       "  '13',\n",
       "  'Tsiolkovsky',\n",
       "  '9/25/2016 22:51'],\n",
       " ['12577787',\n",
       "  'UnGoogled Chromium: Chromium with enhanced privacy, control and transparency',\n",
       "  'https://github.com/Eloston/ungoogled-chromium',\n",
       "  '251',\n",
       "  '120',\n",
       "  'kawera',\n",
       "  '9/25/2016 22:26'],\n",
       " ['12577652',\n",
       "  \"Chelsea Manning's 14 days in solitary for suicide attempt is 'cruel and inhuman'\",\n",
       "  'https://www.amnesty.org.uk/press-releases/chelsea-mannings-14-days-solitary-suicide-attempt-cruel-and-inhuman',\n",
       "  '53',\n",
       "  '34',\n",
       "  'robin_reala',\n",
       "  '9/25/2016 21:51'],\n",
       " ['12577647',\n",
       "  'Ask HN: Someone uses stock trading as passive income?',\n",
       "  '',\n",
       "  '5',\n",
       "  '2',\n",
       "  '00taffe',\n",
       "  '9/25/2016 21:50']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Split our dataset on head and data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****head*****\n",
      " ['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'] \n",
      "*****new hn*****\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['12578311',\n",
       "  'Americas Lost Boys: Men who choose video games over work',\n",
       "  'https://www.firstthings.com/blogs/firstthoughts/2016/08/americas-lost-boys',\n",
       "  '5',\n",
       "  '1',\n",
       "  'jseliger',\n",
       "  '9/26/2016 0:31'],\n",
       " ['12577883',\n",
       "  'LXQt 0.11 Released',\n",
       "  'http://lxqt.org/release/2016/09/24/lxqt-011-et-al/',\n",
       "  '40',\n",
       "  '13',\n",
       "  'Tsiolkovsky',\n",
       "  '9/25/2016 22:51'],\n",
       " ['12577787',\n",
       "  'UnGoogled Chromium: Chromium with enhanced privacy, control and transparency',\n",
       "  'https://github.com/Eloston/ungoogled-chromium',\n",
       "  '251',\n",
       "  '120',\n",
       "  'kawera',\n",
       "  '9/25/2016 22:26'],\n",
       " ['12577652',\n",
       "  \"Chelsea Manning's 14 days in solitary for suicide attempt is 'cruel and inhuman'\",\n",
       "  'https://www.amnesty.org.uk/press-releases/chelsea-mannings-14-days-solitary-suicide-attempt-cruel-and-inhuman',\n",
       "  '53',\n",
       "  '34',\n",
       "  'robin_reala',\n",
       "  '9/25/2016 21:51'],\n",
       " ['12577647',\n",
       "  'Ask HN: Someone uses stock trading as passive income?',\n",
       "  '',\n",
       "  '5',\n",
       "  '2',\n",
       "  '00taffe',\n",
       "  '9/25/2016 21:50']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print('*****head*****\\n', headers, '\\n*****new hn*****')\n",
    "hn[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Filter data\n",
    "Now that we've removed the headers from **hn**, we're ready to filter our data. Since we're only concerned with post titles beginning with *Ask HN* or *Show HN*, we'll create new lists of lists containing just the data for those titles.\n",
    "\n",
    "To find the posts that begin with either *Ask HN* or *Show HN*, we'll use the string method *startswith*. Given a string object, say, *string1*, we can check if starts with, say, *dq* by inspecting the output of the object **string1.startswith('dq')**. If *string1* starts with *dq*, it will return *True*, otherwise it will return *False*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the number of posts **ask_posts**, **show_posts**, and **other posts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ask_posts number:  2064\n",
      "show_posts number:  1455\n",
      "other_posts number:  19828\n"
     ]
    }
   ],
   "source": [
    "print('ask_posts number: ', len(ask_posts))\n",
    "print('show_posts number: ', len(show_posts))\n",
    "print('other_posts number: ', len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Comments range\n",
    "Next, let's determine if ask posts or show posts receive more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average ask_posts comments:  13.570251937984496\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments += num_comments\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print('average ask_posts comments: ', avg_ask_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average show_posts comments:  9.094158075601374\n"
     ]
    }
   ],
   "source": [
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments += num_comments\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print('average show_posts comments: ', avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the average value of **ask_posts** comments is greater than average value of **show_posts**. \n",
    "\n",
    "I think that this difference between the average number of comments is due to the fact that the posts with the request are most often commented out because people will want to help the person who created the message in contrast to the show post where there may be 0 comments under the post.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask posts analysis\n",
    "Since ask posts are more likely to receive comments, we'll focus our remaining analysis just on these posts.\n",
    "\n",
    "Next, we'll determine if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "\n",
    "Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "Calculate the average number of comments ask posts receive by hour created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    result_list.append([row[6], num_comments])\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "for each in result_list:\n",
    "    date_str = each[0]\n",
    "    date_dt = dt.datetime.strptime(date_str, \"%m/%d/%Y %H:%M\")\n",
    "    hour = dt.datetime.strftime(date_dt, \"%H\")\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = each[1]\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += each[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created two dictionaries:\n",
    "\n",
    "**counts_by_hour**: contains the number of ask posts created during each hour of the day.\n",
    "**comments_by_hour**: contains the corresponding number of comments ask posts created at each hour received.\n",
    "***\n",
    "Next, we'll use these two dictionaries to calculate the average number of comments for posts created during each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hour, avg_by_hour]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['21', 10.313868613138686],\n",
       " ['13', 14.710280373831775],\n",
       " ['07', 8.127659574468085],\n",
       " ['22', 14.291666666666666],\n",
       " ['08', 14.352941176470589],\n",
       " ['20', 9.022222222222222],\n",
       " ['18', 10.884615384615385],\n",
       " ['16', 8.807142857142857],\n",
       " ['19', 8.535714285714286],\n",
       " ['17', 16.03361344537815],\n",
       " ['12', 24.185185185185187],\n",
       " ['02', 10.75],\n",
       " ['11', 8.5],\n",
       " ['06', 9.314814814814815],\n",
       " ['23', 9.697368421052632],\n",
       " ['15', 42.148936170212764],\n",
       " ['14', 15.991452991452991],\n",
       " ['09', 4.1063829787234045],\n",
       " ['00', 9.7],\n",
       " ['03', 7.775862068965517],\n",
       " ['10', 12.203125],\n",
       " ['05', 9.211538461538462],\n",
       " ['01', 10.791044776119403],\n",
       " ['04', 10.23404255319149]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for each in counts_by_hour:\n",
    "    avg_by_hour.append([each, comments_by_hour[each]/counts_by_hour[each]])\n",
    "print('[hour, avg_by_hour]')\n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we now have the results we need, this format makes it hard to identify the hours with the highest values. Let's finish by sorting the list of lists and printing the five highest values in a format that's easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[avg_by_hour, hour]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[10.313868613138686, '21'],\n",
       " [14.710280373831775, '13'],\n",
       " [8.127659574468085, '07'],\n",
       " [14.291666666666666, '22'],\n",
       " [14.352941176470589, '08'],\n",
       " [9.022222222222222, '20'],\n",
       " [10.884615384615385, '18'],\n",
       " [8.807142857142857, '16'],\n",
       " [8.535714285714286, '19'],\n",
       " [16.03361344537815, '17'],\n",
       " [24.185185185185187, '12'],\n",
       " [10.75, '02'],\n",
       " [8.5, '11'],\n",
       " [9.314814814814815, '06'],\n",
       " [9.697368421052632, '23'],\n",
       " [42.148936170212764, '15'],\n",
       " [15.991452991452991, '14'],\n",
       " [4.1063829787234045, '09'],\n",
       " [9.7, '00'],\n",
       " [7.775862068965517, '03'],\n",
       " [12.203125, '10'],\n",
       " [9.211538461538462, '05'],\n",
       " [10.791044776119403, '01'],\n",
       " [10.23404255319149, '04']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for each in avg_by_hour:\n",
    "    swap_avg_by_hour.append([each[1], each[0]])\n",
    "print('[avg_by_hour, hour]')\n",
    "swap_avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 42.15 average comments per post\n",
      "12:00: 24.19 average comments per post\n",
      "17:00: 16.03 average comments per post\n",
      "14:00: 15.99 average comments per post\n",
      "13:00: 14.71 average comments per post\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "print('Top 5 Hours for Ask Posts Comments')\n",
    "for each in sorted_swap[0:5]:\n",
    "    date_str = each[1]\n",
    "    date_dt = dt.datetime.strptime(date_str, \"%H\")\n",
    "    time = dt.datetime.strftime(date_dt, \"%H:%M\")\n",
    "    print('{}: {:.2f} average comments per post'.format(time, each[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "As we can see, your post is more likely to be commented on, and your question was answered in a timely manner, you need to post posts and ask questions at 15:00. If you do not have such an opportunity, then try to manage to do what is planned between 12:00 and 17:00 - at this time the most discussed and most active posts are published"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
